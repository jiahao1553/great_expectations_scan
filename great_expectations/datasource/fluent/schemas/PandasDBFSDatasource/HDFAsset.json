{
    "title": "HDFAsset",
    "description": "Read from the store, close it if we opened it.\n\nRetrieve pandas object stored in file, optionally based on where\ncriteria.\n\n.. warning::\n\n   Pandas uses PyTables for reading and writing HDF5 files, which allows\n   serializing object-dtype data with pickle when using the \"fixed\" format.\n   Loading pickled data received from untrusted sources can be unsafe.\n\n   See: https://docs.python.org/3/library/pickle.html for more.\n\nParameters\n----------\npath_or_buf : str, path object, pandas.HDFStore\n    Any valid string path is acceptable. Only supports the local file system,\n    remote URLs and file-like objects are not supported.\n\n    If you want to pass in a path object, pandas accepts any\n    ``os.PathLike``.\n\n    Alternatively, pandas accepts an open :class:`pandas.HDFStore` object.\n\nkey : object, optional\n    The group identifier in the store. Can be omitted if the HDF file\n    contains a single pandas object.\nmode : {'r', 'r+', 'a'}, default 'r'\n    Mode to use when opening the file. Ignored if path_or_buf is a\n    :class:`pandas.HDFStore`. Default is 'r'.\nerrors : str, default 'strict'\n    Specifies how encoding and decoding errors are to be handled.\n    See the errors argument for :func:`open` for a full list\n    of options.\nwhere : list, optional\n    A list of Term (or convertible) objects.\nstart : int, optional\n    Row number to start selection.\nstop  : int, optional\n    Row number to stop selection.\ncolumns : list, optional\n    A list of columns names to return.\niterator : bool, optional\n    Return an iterator object.\nchunksize : int, optional\n    Number of rows to include in an iteration when using an iterator.\n**kwargs\n    Additional keyword arguments passed to HDFStore.\n\nReturns\n-------\nitem : object\n    The selected object. Return type depends on the object stored.\n\nSee Also\n--------\nDataFrame.to_hdf : Write a HDF file from a DataFrame.\nHDFStore : Low-level access to HDF files.\n\nExamples\n--------\n>>> df = pd.DataFrame([[1, 1.0, 'a']], columns=['x', 'y', 'z'])  # doctest: +SKIP\n>>> df.to_hdf('./store.h5', 'data')  # doctest: +SKIP\n>>> reread = pd.read_hdf('./store.h5')  # doctest: +SKIP",
    "type": "object",
    "properties": {
        "name": {
            "title": "Name",
            "type": "string"
        },
        "type": {
            "title": "Type",
            "default": "hdf",
            "enum": [
                "hdf"
            ],
            "type": "string"
        },
        "id": {
            "title": "Id",
            "description": "DataAsset id",
            "type": "string",
            "format": "uuid"
        },
        "order_by": {
            "title": "Order By",
            "type": "array",
            "items": {
                "$ref": "#/definitions/Sorter"
            }
        },
        "batch_metadata": {
            "title": "Batch Metadata",
            "type": "object"
        },
        "batching_regex": {
            "title": "Batching Regex",
            "default": ".*",
            "type": "string",
            "format": "regex"
        },
        "connect_options": {
            "title": "Connect Options",
            "description": "Optional filesystem specific advanced parameters for connecting to data assets",
            "type": "object"
        },
        "splitter": {
            "title": "Splitter",
            "anyOf": [
                {
                    "$ref": "#/definitions/SplitterColumnValue"
                },
                {
                    "$ref": "#/definitions/SplitterMultiColumnValue"
                },
                {
                    "$ref": "#/definitions/SplitterDividedInteger"
                },
                {
                    "$ref": "#/definitions/SplitterModInteger"
                },
                {
                    "$ref": "#/definitions/SplitterYear"
                },
                {
                    "$ref": "#/definitions/SplitterYearAndMonth"
                },
                {
                    "$ref": "#/definitions/SplitterYearAndMonthAndDay"
                },
                {
                    "$ref": "#/definitions/SplitterDatetimePart"
                }
            ]
        },
        "key": {
            "title": "Key"
        },
        "mode": {
            "title": "Mode",
            "default": "r",
            "type": "string"
        },
        "errors": {
            "title": "Errors",
            "default": "strict",
            "type": "string"
        },
        "where": {
            "title": "Where",
            "anyOf": [
                {
                    "type": "string"
                },
                {
                    "type": "array",
                    "items": {}
                }
            ]
        },
        "start": {
            "title": "Start",
            "type": "integer"
        },
        "stop": {
            "title": "Stop",
            "type": "integer"
        },
        "columns": {
            "title": "Columns",
            "type": "array",
            "items": {
                "type": "string"
            }
        },
        "iterator": {
            "title": "Iterator",
            "default": false,
            "type": "boolean"
        },
        "chunksize": {
            "title": "Chunksize",
            "type": "integer"
        },
        "kwargs": {
            "title": "Kwargs",
            "description": "Extra keyword arguments that will be passed to the reader method",
            "type": "object"
        }
    },
    "required": [
        "name"
    ],
    "additionalProperties": false,
    "definitions": {
        "Sorter": {
            "title": "Sorter",
            "type": "object",
            "properties": {
                "key": {
                    "title": "Key",
                    "type": "string"
                },
                "reverse": {
                    "title": "Reverse",
                    "default": false,
                    "type": "boolean"
                }
            },
            "required": [
                "key"
            ]
        },
        "SplitterColumnValue": {
            "title": "SplitterColumnValue",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_name": {
                    "title": "Column Name",
                    "type": "string"
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_column_value",
                    "enum": [
                        "split_on_column_value"
                    ],
                    "type": "string"
                }
            },
            "required": [
                "column_name"
            ],
            "additionalProperties": false
        },
        "SplitterMultiColumnValue": {
            "title": "SplitterMultiColumnValue",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_names": {
                    "title": "Column Names",
                    "type": "array",
                    "items": {
                        "type": "string"
                    }
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_multi_column_values",
                    "enum": [
                        "split_on_multi_column_values"
                    ],
                    "type": "string"
                }
            },
            "required": [
                "column_names"
            ],
            "additionalProperties": false
        },
        "SplitterDividedInteger": {
            "title": "SplitterDividedInteger",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_name": {
                    "title": "Column Name",
                    "type": "string"
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_divided_integer",
                    "enum": [
                        "split_on_divided_integer"
                    ],
                    "type": "string"
                },
                "divisor": {
                    "title": "Divisor",
                    "type": "integer"
                }
            },
            "required": [
                "column_name",
                "divisor"
            ],
            "additionalProperties": false
        },
        "SplitterModInteger": {
            "title": "SplitterModInteger",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_name": {
                    "title": "Column Name",
                    "type": "string"
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_mod_integer",
                    "enum": [
                        "split_on_mod_integer"
                    ],
                    "type": "string"
                },
                "mod": {
                    "title": "Mod",
                    "type": "integer"
                }
            },
            "required": [
                "column_name",
                "mod"
            ],
            "additionalProperties": false
        },
        "SplitterYear": {
            "title": "SplitterYear",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_name": {
                    "title": "Column Name",
                    "type": "string"
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_year",
                    "enum": [
                        "split_on_year"
                    ],
                    "type": "string"
                }
            },
            "required": [
                "column_name"
            ],
            "additionalProperties": false
        },
        "SplitterYearAndMonth": {
            "title": "SplitterYearAndMonth",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_name": {
                    "title": "Column Name",
                    "type": "string"
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_year_and_month",
                    "enum": [
                        "split_on_year_and_month"
                    ],
                    "type": "string"
                }
            },
            "required": [
                "column_name"
            ],
            "additionalProperties": false
        },
        "SplitterYearAndMonthAndDay": {
            "title": "SplitterYearAndMonthAndDay",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_name": {
                    "title": "Column Name",
                    "type": "string"
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_year_and_month_and_day",
                    "enum": [
                        "split_on_year_and_month_and_day"
                    ],
                    "type": "string"
                }
            },
            "required": [
                "column_name"
            ],
            "additionalProperties": false
        },
        "SplitterDatetimePart": {
            "title": "SplitterDatetimePart",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "column_name": {
                    "title": "Column Name",
                    "type": "string"
                },
                "method_name": {
                    "title": "Method Name",
                    "default": "split_on_date_parts",
                    "enum": [
                        "split_on_date_parts"
                    ],
                    "type": "string"
                },
                "datetime_parts": {
                    "title": "Datetime Parts",
                    "type": "array",
                    "items": {
                        "type": "string"
                    }
                }
            },
            "required": [
                "column_name",
                "datetime_parts"
            ],
            "additionalProperties": false
        }
    }
}
